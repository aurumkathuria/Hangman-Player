{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Before diving in to this, just a few things to note:**\n",
    "\n",
    "1) Up to Cell 3 is everything to guess a word given its length, the 10,000 word list, and the code.\n",
    "\n",
    "2) After Cell 3 is my attempt at using a algorithm to try and maximize word-guessing accuracy. I did a lot of work to try and figure out how best to approach the problem, which can be seen in Cells 4, 5, and 6. I then tried to implement that solution, which can be found in Cells 7 and 8. However, as detailed in the write-up for this project on my GitHub (bit.ly/Hangman-Player), that whole thing was wrong and based on very faulty assumptions. I'd still like to think the code and conceptualization behind the idea is cool, but I need some different data in order to really make use of this at all. Til that day comes though, feel free to mess around with this and see what you can do!  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import math\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='google-10000-english/google-10000-english-no-swears.txt' mode='r' encoding='cp1252'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>for</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>on</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>that</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  words\n",
       "0   the\n",
       "1    of\n",
       "2   and\n",
       "3    to\n",
       "4     a\n",
       "5    in\n",
       "6   for\n",
       "7    is\n",
       "8    on\n",
       "9  that"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = \"google-10000-english/google-10000-english-no-swears.txt\"\n",
    "print(open(filepath))\n",
    "\n",
    "import ast\n",
    "filepath = \"google-10000-english/google-10000-english-no-swears.txt\"\n",
    "words_set = pd.read_csv(filepath, names=['words'])\n",
    "words_set = words_set.iloc[:]\n",
    "words_set = words_set.dropna()\n",
    "words_set = words_set.drop(1820)\n",
    "words_set.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4 guesses to get apple'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#function that handles guessing the word and returns the number of guesses made     \n",
    "\n",
    "# hangman is the word we're trying to find, need to eventually replace with user input\n",
    "def guess_word(hangman, blanks=None, possible_words=pd.DataFrame(), guesses=[]): \n",
    "\n",
    "    # possible_words: a set of words of length n, dtype: \n",
    "    # blanks: a set of known letters for the words, dtype: \n",
    "    # OBJECTIVE: to find a new set of words that meets the requirements outlined in blanks\n",
    "    \n",
    "    def get_word_options(possible_words):  \n",
    "        blank_dict = {}\n",
    "        # create a dictionary for blanks that states the value at the index; if none, then nothing is put\n",
    "        for a in range(len(blanks)):\n",
    "            if blanks[a] != \"\":\n",
    "                blank_dict[a] = blanks[a]\n",
    "        #print(blank_dict)\n",
    "\n",
    "        #see what words meet blanks' requirements\n",
    "        col_list = [\"word\", \"word freq\"]\n",
    "        word_list = []\n",
    "        word_freq_list = []\n",
    "        for i in range(len(possible_words)): # for each word in possible_words\n",
    "            word = possible_words.iloc[i][0]\n",
    "            word_freq = possible_words.iloc[i][1]\n",
    "            meets_req = True\n",
    "            for jndex in blank_dict: # for each index in blank_dict \n",
    "                if word[jndex] != blank_dict[jndex]:\n",
    "                    meets_req = False\n",
    "            if meets_req:\n",
    "                word_list.append(word)\n",
    "                word_freq_list.append(word_freq)\n",
    "        word_ops = pd.DataFrame(data = {\"word\": np.array(word_list), \"word_freq\": np.array(word_freq_list)})\n",
    "        return word_ops\n",
    "\n",
    "    # create a dictionary that has the frequency of each letter from the word_options to determine the optimal guesses \n",
    "    def get_guess(word, word_ops):\n",
    "        assert isinstance(word, list), \"the incoming word must be a list\"\n",
    "        letter_dict = {'a':0, 'b':0, 'c':0, 'd':0, 'e':0, \n",
    "                          'f':0, 'g':0, 'h':0, 'i':0, 'j':0, \n",
    "                          'k':0, 'l':0, 'm':0, 'n':0, 'o':0, \n",
    "                          'p':0, 'q':0, 'r':0, 's':0, 't':0, \n",
    "                          'u':0, 'v':0, 'w':0, 'x':0, 'y':0, 'z':0}\n",
    "        for guessed_letter in guesses:\n",
    "            letter_dict[guessed_letter] = -1\n",
    "        for i in range(len(word_ops)):\n",
    "            curr_word = word_ops.iloc[i][0]\n",
    "            word_freq = word_ops.iloc[i][1]\n",
    "            for j in range(len(curr_word)):\n",
    "                curr_letter = curr_word[j]\n",
    "                if letter_dict.get(curr_letter, 0) == 0:\n",
    "                    letter_dict[curr_letter] = 0\n",
    "                letter_dict[curr_letter] = letter_dict[curr_letter] + word_freq\n",
    "        for letter in blanks:\n",
    "            if letter:\n",
    "                letter_dict[letter] = -1\n",
    "        return letter_dict\n",
    "\n",
    "    # purpose: to guess a letter for the word\n",
    "    # method: guess the letter with the highest frequency from the dict; if that doesn't work, guess the next highest, recursively.\n",
    "    def make_guess(dict_in):\n",
    "        nonlocal guesses\n",
    "        curr_guess = key_of_max_val(dict_in)[0]\n",
    "        guesses.append(curr_guess)\n",
    "        if dict_in[curr_guess] == -1:\n",
    "            raise WordNotInDictionaryError(\"We're unable to determine your word, but here's what we have so far: \" + str(guess_dict))\n",
    "        correct, word = guess_letter(curr_guess, blanks)\n",
    "        if not(correct):\n",
    "            dict_in[curr_guess] = -1\n",
    "            return make_guess(dict_in)\n",
    "        else:\n",
    "            return word\n",
    "\n",
    "    # this method returns whether the guessed letter is in the word, and the thus-filled word after the guess\n",
    "    def guess_letter(letter, word):\n",
    "        in_hangman = False\n",
    "        if letter in hangman:\n",
    "            in_hangman = True\n",
    "            indices = []\n",
    "            for i in range(len(hangman)):\n",
    "                if letter == hangman[i]:\n",
    "                    indices.append(i)\n",
    "            for i in indices:\n",
    "                word[i] = letter\n",
    "        return in_hangman, word\n",
    "\n",
    "    #see if the guessed word is the same as the word input to the program by inspecting it letter-by-letter\n",
    "    def test_success(word, hangman):\n",
    "        for i in range(len(hangman)):\n",
    "            if word[i] != hangman[i]:\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    #UTILITY FUNCTIONS\n",
    "    def init_freq_model(slope, intercept):\n",
    "        #create words_details, which is a table containing a word, its frequency assignment, and its length\n",
    "        words_details = words_set.iloc[:]\n",
    "        word_deet_len = len(words_details)\n",
    "        words_details['word freq'] = np.array([intercept*word_deet_len + slope*i for i in range(word_deet_len)])\n",
    "        words_details['word length'] = np.array([len(words_set.iloc[i][0]) for i in range(word_deet_len)])\n",
    "        #print(words_details.head()) #prints the words_details table\n",
    "        return words_details[words_details['word length'] == len(blanks)][:]        \n",
    "            \n",
    "    #custom exception for this program \n",
    "    class WordNotInDictionaryError(Exception):\n",
    "        def __init__(self, value):\n",
    "            self.value = value\n",
    "        def __str__(self):\n",
    "            print(\"Uh oh! Looks like you've tried to put in a word that's \" + \n",
    "                  \"not in our dictionary. Double check the spelling just in case, \" + \n",
    "                  \"but keep in mind that our dictionary is limited to only 10,000 words, \" +\n",
    "                  \"so we may just not have that word quite yet!\")\n",
    "            return repr(self.value)\n",
    "        \n",
    "    def key_of_max_val(dict_in):\n",
    "        \"\"\"\n",
    "        >>> test_dict = {'a': 1, 'b': 2, 'c':5, 'd': 3}\n",
    "        >>> print(key_of_max_val(test_dict))\n",
    "        c \n",
    "        \"\"\"\n",
    "        #this function returns the key that has the highest value in a dictionary\n",
    "        max_val = [key for key in dict_in if dict_in[key] ==  max([dict_in[key] for key in dict_in])  ]\n",
    "        return max_val\n",
    "    #end utility functions\n",
    "    \n",
    "    #next 4 lines only happen in the first iteration\n",
    "    if not blanks: # this is a baseline for the parts of the word we've guessed so far\n",
    "        blanks = [\"\"]*len(hangman)\n",
    "    if possible_words.empty: #this a baseline for the words that hangman could be\n",
    "        possible_words = init_freq_model(-1, 1)\n",
    "\n",
    "    #these next few lines call the methods that run the word-finding process\n",
    "    #first, we find all words that are of the same length as the input word, and that match the correct guesses thus far\n",
    "    #next, we take those words, and we extract the frequencies of letters from those words\n",
    "    #then, we guess the most common letter\n",
    "    #finally, when we've completed the word, we return how many guesses we made\n",
    "    word_options = get_word_options(possible_words)              #first\n",
    "    guess_dict = get_guess(blanks, word_options)                 #next\n",
    "    word = make_guess(guess_dict)                                #then\n",
    "    if test_success(word, hangman):                              #then\n",
    "        return str(len(guesses)) + \" guesses to get \" + hangman  #finally\n",
    "    else:                                                        #then\n",
    "        return guess_word(hangman, word, word_options, guesses)  #then\n",
    "    \n",
    "guess_word('apple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the optimal frequency to guess words fastest and using the fewest steps\n",
    "#changing frequency through a rotation and seeing the output and making choices based on it\n",
    "#finding effectiveness by taking the Guess Success Ratio (GSR) -> guesses/UNIQUE letters in word (try 'school' to see why)\n",
    "#lowest GSR \"wins\"\n",
    "#three trials per Frequency Model on a set of 500 words randomly selected from the 10,000 word set\n",
    "#first, build one operational model \n",
    "#then, transform key values of variables to see how effective things are\n",
    "#finally, test data and wait to see what happens\n",
    "#let's begin!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"          \n",
    "                 a   b\n",
    "                     d   e\n",
    "                 c       g\n",
    "                     f          \n",
    "                                       \n",
    "                                               \n",
    "                                                    •\n",
    "                        \n",
    "                        \n",
    "first, we take the three points as our starters\n",
    "we find the rate of change between them, (∆GSR/∆slope or ∆intercept)\n",
    "move in the direction of the change between points times the rates of change\n",
    "a(0,0) = 10\n",
    "b(1,0) = 9\n",
    "c(0,1) = 9.5\n",
    "∆ab = 1/1   = 1               #a - b\n",
    "∆ac = 0.5/1 = -0.5           #a - c\n",
    "(b-a)*∆ab = <1,0>*1   = <1,0>\n",
    "(c-a)*∆ac = <0,1>*0.5 = <0,0.5>\n",
    "d(1,0.5) = 8.5\n",
    "e(2,0.5) = 7.5\n",
    "f(1,1.5) = 8\n",
    "∆de = 1/1   = 1\n",
    "∆df = 0.5/1 = 0.5\n",
    "(e-d)*∆de = <1,0>*1   = <1,0>\n",
    "(f-d)*∆df = <0,1>*0.5 = <0,0.5>\n",
    "<1,0> + <0,0.5> = <1,0.5>\n",
    "<1,0.5>+<1,0.5> = <2,1>\n",
    "g(2,1)\n",
    "...\n",
    "...\n",
    "...\n",
    "\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"def test_values(slope, intercept):\n",
    "    ##   a = slope*b + intercept   ##\n",
    "    # optimal values are: slope=6.2, intercept=7.5\n",
    "    return abs((slope-6.2)) + abs((intercept-7.5))\n",
    "    \n",
    "class XYZ:\n",
    "    def __init__(self, slope, intercept, gsr):\n",
    "        self.slope = slope\n",
    "        self.intercept = intercept\n",
    "        self.gsr = gsr\n",
    "    \n",
    "def optimize():\n",
    "    run_count = 0\n",
    "    def optimize_slope(min_slope, max_slope, intercept):\n",
    "        nonlocal run_count\n",
    "        mean_slope, gsr_dict = (min_slope + max_slope)/2, {} \n",
    "        slope_dict = {\"min_slope\": min_slope, \"max_slope\": max_slope}  #, \"mean_slope\": mean_slope}\n",
    "        for key in slope_dict:\n",
    "            slope = slope_dict[key]\n",
    "            if slope in output_dict:\n",
    "                gsr_dict[slope] = output_dict[slope]\n",
    "            else:\n",
    "                run_count += 1\n",
    "                gsr_dict[slope] = test_values(slope, intercept)\n",
    "        print(\"min_slope:\", slope_dict[\"min_slope\"], \"gsr_min:\", gsr_dict[slope_dict[\"min_slope\"]])\n",
    "        print(\"max_slope:\", slope_dict[\"max_slope\"], \"gsr_max:\", gsr_dict[slope_dict[\"max_slope\"]])\n",
    "        #print(\"mean_slope:\",slope_dict[\"mean_slope\"],\"gsr_mean:\",gsr_dict[slope_dict[\"mean_slope\"]])\n",
    "        #gsr_dict = {min_slope: gsr_min, max_slope: gsr_max, mean_slope: gsr_mean}\n",
    "        return gsr_dict\n",
    "\n",
    "    def optimize_slope(min_int, max_int, slope):\n",
    "        nonlocal run_count\n",
    "        mean_int, gsr_dict = (min_int + max_int)/2, {} \n",
    "        slope_dict = {\"min_int\": min_int, \"max_int\": max_int}     #, \"mean_int\": mean_int}\n",
    "        for key in slope_dict:\n",
    "            slope = slope_dict[key]\n",
    "            if slope in output_dict:\n",
    "                gsr_dict[slope] = output_dict[slope]\n",
    "            else:\n",
    "                run_count += 1\n",
    "                gsr_dict[slope] = test_values(slope, intercept)\n",
    "        print(\"min_int:\", slope_dict[\"min_int\"], \"gsr_min:\", gsr_dict[slope_dict[\"min_int\"]])\n",
    "        print(\"max_int:\", slope_dict[\"max_int\"], \"gsr_max:\", gsr_dict[slope_dict[\"max_int\"]])\n",
    "        #print(\"mean_int:\",slope_dict[\"mean_int\"],\"gsr_mean:\",gsr_dict[slope_dict[\"mean_int\"]])\n",
    "        #gsr_dict = {min_int: gsr_min, max_int: gsr_max, mean_int: gsr_mean}\n",
    "        return gsr_dict\n",
    "    \n",
    "    def remove_and_print_biggest(dict_in):\n",
    "        print( \"biggest:\", dict_in.pop([key for key in dict_in if dict_in[key] ==  max([dict_in[key] for key in dict_in])  ][0]) )\n",
    "    \n",
    "    def key_of_fn_val(dict_in, fn):\n",
    "        return [key for key in dict_in if dict_in[key] ==  fn([dict_in[key] for key in dict_in])  ][0]\n",
    "    \n",
    "    def update_dict_from_another(dict_to, dict_from):\n",
    "        for key in dict_from:                   # for each key in the dict we're copying from\n",
    "            if key not in dict_to:              # if they key isn't in the dictionary we're copying to\n",
    "                dict_to[key] = dict_from[key]   # copy the key-value pair to the other dictionary\n",
    "    \n",
    "    def return_statement(dict_in):    \n",
    "        min_val_key = [key for key in dict_in if dict_in[key] ==  min([dict_in[key] for key in dict_in])  ][0]\n",
    "        smallest_output = min([dict_in[key] for key in dict_in])\n",
    "        biggest_output = max([dict_in[key] for key in dict_in])\n",
    "        print(\"run_count:\", run_count)\n",
    "        return min_val_key, smallest_output, biggest_output-smallest_output, dict_in\n",
    "    \n",
    "    margin_of_error, intercept = 0.1, 5.5\n",
    "    dict_in, output_dict = {0:50, 10:100, 61:715}, {} #starting guesses for dictionary (values useless)\n",
    "    while max([dict_in[key] for key in dict_in]) - min([dict_in[key] for key in dict_in]) > margin_of_error:\n",
    "        remove_and_print_biggest(dict_in)                                   #remove the least accurate guess\n",
    "        min_val_key = key_of_fn_val(dict_in, min)                           #get the key with the smallest value\n",
    "        max_val_key = key_of_fn_val(dict_in, max)                           #get the key with the largest value\n",
    "        dict_in = optimize_slope(min_val_key, max_val_key, intercept)       #test the new values\n",
    "        update_dict_from_another(output_dict, dict_in)                      #update memoized dictionary from the slope/gsr dict\n",
    "        print(\"memoized dictionary:\", output_dict)                          #print memoized dictionary\n",
    "        print(\"new_updates:\", dict_in)                                      #print slope/gsr dictionary\n",
    "        \n",
    "    return return_statement(dict_in)\n",
    "\n",
    "#make note of when the answer is very close to the boundary, means boundary change is needed\n",
    "print('Begin!')        \n",
    "optimize()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "raw_mimetype": "text/x-python"
   },
   "outputs": [],
   "source": [
    "def test_runner(slope, intercept): #this function runs the various tests of the program to determine the GSR of the Frequency Model\n",
    "    \n",
    "    #interval -> at what percent to print\n",
    "    #obj_size -> how big the object is\n",
    "    #curr_pos -> how far through the object calculations are\n",
    "    #addendum -> the string to print after 'n% completed'\n",
    "    def completion_updater(interval, obj_size, curr_pos, addendum):\n",
    "        if curr_pos % (obj_size//interval) == 0 or curr_pos == obj_size:\n",
    "            completion = (curr_pos*100)//obj_size\n",
    "            print(\"{0:3d}% completed\".format(completion), addendum)\n",
    "            \n",
    "#-------------------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "    #samples the words_details to get a list of 500 random words to test\n",
    "    def get_random_sample(words_details, num_samples=500):\n",
    "        sampled_words_df = words_details.sample(n=num_samples)\n",
    "        print(num_samples, \"words generated to test\")\n",
    "        return [sampled_words_df.iloc[i][0] for i in range(num_samples)]\n",
    "    \n",
    "    def init_freq_model(slope, intercept):\n",
    "        #create words_details, which is a table containing a word, its frequency assignment, and its length\n",
    "        words_details = words_set.iloc[:]\n",
    "        word_deet_len = len(words_details)\n",
    "        words_details['word freq'] = np.array([intercept*word_deet_len + slope*i for i in range(word_deet_len)])\n",
    "        words_details['word length'] = np.array([len(words_set.iloc[i][0]) for i in range(word_deet_len)])\n",
    "        #print(words_details.head()) #prints the words_details table\n",
    "        return words_details\n",
    "    \n",
    "    #central method code. this does the testing for 500 random words 5 times\n",
    "    #get and print start time\n",
    "    start_time = datetime.datetime.now()\n",
    "    print(\"start at\", start_time) #start time\n",
    "    \n",
    "    #get the words_details table\n",
    "    words_details = init_freq_model(slope, intercept)\n",
    "    \n",
    "    #decide how many reruns and samples to use\n",
    "    reruns, sampling_size = 5, 500\n",
    "    \n",
    "    #test the model to find the gsr (Guesses to Successful guesses Ratio)\n",
    "    gsr_list_onesetting = [] #the gsr's of a specific setting\n",
    "    for i in range(1, reruns+1):\n",
    "        gsr_list_onerun = [] #the gsr's of a specific run\n",
    "        rand_word_list = get_random_sample(words_details, sampling_size) #get a list of random words to test the model on\n",
    "        rand_word_list_len = len(rand_word_list)\n",
    "        print(\"RUNNING TEST #\" + str(i)) \n",
    "        \n",
    "        #test the words in the run\n",
    "        count = 0\n",
    "        for j in range(rand_word_list_len):\n",
    "            completion_updater(4, sampling_size, j, \"(\" + str(datetime.datetime.now()) + \")\") #print the % done and time\n",
    "            word = rand_word_list[j] #get the specific word to try\n",
    "            word_len = len(word) \n",
    "            guesses = int(guess_word(word)[0]) #get the number of guesses to get the word\n",
    "            gsr = guesses/word_len #calculate the gsr\n",
    "            gsr_list_onerun.append(gsr) #append the gsr to the list of gsr's for this run\n",
    "            \n",
    "        av_gsr_onerun = sum(gsr_list_onerun)/float(len(gsr_list_onerun)) #calculate the average gsr of the run\n",
    "        print(\"TEST {0} GSR: {1:7.4} computed in {2:10.5}\".format(i, av_gsr_onerun, str(datetime.datetime.now() - start_time))) \n",
    "        gsr_list_onesetting.append(av_gsr_onerun) #append the gsr to the list of gsr's for this setting\n",
    "        \n",
    "    av_gsr_onesetting = sum(gsr_list_onesetting)/float(len(gsr_list_onesetting)) #calculate the average gsr of the setting\n",
    "    end_time = datetime.datetime.now()\n",
    "    print(\"end at\", end_time) #start time\n",
    "    print(\"TOTAL TIME ELAPSED\", end_time - start_time) #show the time elapsed for the setting\n",
    "    print(\"GSR FOR FREQ MODEL S= \" + str(round(slope, 5)) + \",I=\" + str(round(intercept, 5)) + \": \" + str(round(av_gsr_onesetting, 5)))\n",
    "    print('\\n\\n\\n\\n')\n",
    "    return av_gsr_onesetting #return the average gsr of the setting \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    #ALTERNATE CODE (less testing capabilities): gsr_one_test = [guess_word(word)/len(word) for word in rand_word_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class XYZ:\n",
    "    gsr = ()\n",
    "    def __init__(self, x, y):\n",
    "        self.slope = x \n",
    "        self.intercept = y\n",
    "    \n",
    "    def get_gsr(self):\n",
    "        if not self.has_gsr():\n",
    "            #print(\"testing for gsr!\")\n",
    "            gsr = test_values(self.slope, self.intercept)\n",
    "            self.update_gsr(gsr)\n",
    "        \n",
    "    def update_gsr(self, gsr):\n",
    "        self.gsr = gsr\n",
    "        #print(\"gsr set to:\", gsr)\n",
    "        \n",
    "    def has_gsr(self):\n",
    "        return self.gsr != ()\n",
    "    \n",
    "    def del_gsr(self, base):\n",
    "        if not(self.has_gsr()): #when self missing gsr\n",
    "            #print(\"getting self gsr!\") \n",
    "            self.get_gsr()\n",
    "        if not(base.has_gsr()): #when other missing gsr\n",
    "            #print(\"getting other gsr!\")\n",
    "            base.get_gsr()\n",
    "        #when both have gsr, return the difference between other and self\n",
    "        #print(\"gsr difference:\", base.gsr - self.gsr, \" = base.gsr (\" + str(base.gsr) + \") - self.gsr (\" + str(self.gsr) + \")\")\n",
    "        return base.gsr - self.gsr\n",
    "            \n",
    "    def del_pos_sum(self, base):\n",
    "        #print(\"getting positional sum\")\n",
    "        #print(\"intercepts:\", self.intercept, base.intercept)\n",
    "        #print(\"slope:\", self.slope, base.slope)\n",
    "        return (self.intercept - base.intercept) + (self.slope - base.slope)\n",
    "    \n",
    "    def del_pos_vector(self, base):\n",
    "        #print(\"creating positional difference vector!\")\n",
    "        #print([base.intercept - self.intercept, base.slope - self.slope])\n",
    "        return [base.slope - self.slope, base.intercept - self.intercept]\n",
    "    \n",
    "    def differential(self, base):\n",
    "        del_gsr = self.del_gsr(base)\n",
    "        del_pos = self.del_pos_sum(base)\n",
    "        #print(\"del_gsr:\", del_gsr, \"del_pos\", del_pos)\n",
    "        diff = del_gsr/del_pos\n",
    "        #print(\"gsr differential:\", diff)\n",
    "        return diff\n",
    "        \n",
    "    def delta_vector(self, p1, p2):\n",
    "        vector1 = self.del_pos_vector(p1)\n",
    "        #print(\"vector for b\", vector1)\n",
    "        vector2 = self.del_pos_vector(p2)\n",
    "        #print(\"vector for c\", vector2)\n",
    "        differential1 = p1.differential(self)\n",
    "        #print(\"differential for b\", differential1)\n",
    "        differential2 = p2.differential(self)\n",
    "        #print(\"differential for c\", differential2)\n",
    "        vector = [0, 0]\n",
    "        vector[0] = round(differential1*vector1[0] + differential2*vector2[0], 5)\n",
    "        vector[1] = round(differential1*vector1[1] + differential2*vector2[1], 5)\n",
    "        #print(\"change vector:\", vector)\n",
    "        return vector\n",
    "\n",
    "    #create secondary and tertiary points\n",
    "    def get_points(self): # self is the starting point\n",
    "        #change_factor = math.sqrt(abs(self.gsr-3))\n",
    "        change_factor = 1/(0.1 + 4*pow(0.7, self.gsr))-0.244 \n",
    "        b = XYZ(self.slope + change_factor, self.intercept)\n",
    "        c = XYZ(self.slope, self.intercept + change_factor)\n",
    "        b.get_gsr()\n",
    "        c.get_gsr()\n",
    "        print(\"B COORDINATES:\", b)\n",
    "        print(\"C COORDINATES\", c)\n",
    "        #print(\"change_factor\", change_factor)\n",
    "        return b, c\n",
    "    \n",
    "    def create_new_base(self):\n",
    "        b, c = self.get_points()\n",
    "        coord_change_values = self.delta_vector(b, c)\n",
    "        curr_coord = [self.slope, self.intercept]\n",
    "        new_coord = [curr_coord[0]+coord_change_values[0], curr_coord[1]+coord_change_values[1]]\n",
    "        return XYZ(new_coord[0], new_coord[1])\n",
    "    \n",
    "    def __repr__(self):\n",
    "        slope_and_int = \"Slope: \" + str(round(self.slope, 5)) + \"  Intercept: \" + str(round(self.intercept, 5))\n",
    "        if self.has_gsr():\n",
    "            return slope_and_int + \"  GSR: \" +  str(round(self.gsr, 5))\n",
    "        return slope_and_int\n",
    "            \n",
    "    def __str__(self):\n",
    "        return self.__repr__()\n",
    "        \n",
    "#------------------------------------------------------------------------------------------------------------------------------#\n",
    "def test_values(slope, intercept):\n",
    "    ##   a = slope*b + intercept   ##\n",
    "    # optimal values are: \n",
    "    return test_runner(slope, intercept)\n",
    "    \n",
    "def optimize_slope_and_intercept():\n",
    "    print(\"Beginning Optimization Procedures!\")\n",
    "    base = XYZ(-1, 1) \n",
    "    base.get_gsr()\n",
    "    margin_of_error = 0.1\n",
    "    run_count = 0\n",
    "    while base.gsr > margin_of_error+1 and run_count < 20:\n",
    "        print(\"\\nNEW BASE COORDINATES\", base)\n",
    "        base = base.create_new_base()\n",
    "        base.get_gsr()\n",
    "        run_count += 3\n",
    "    print(\"--------------------------------\")\n",
    "    print(\"final base:\", base)\n",
    "    print(\"run_count\", run_count)\n",
    "    return base, run_count\n",
    "\n",
    "start_time = datetime.datetime.now()\n",
    "final_base, computations = optimize_slope_and_intercept()\n",
    "end_time = atetime.datetime.now()\n",
    "print('\\n\\n\\n\\n')\n",
    "print(\"Optimal Solution:\", final_base)\n",
    "print(\"computed in\", run_count, \"iterations.\")\n",
    "print(\"Total Time Elapsed:\", end_time - start_time, \"(from \" + start_time + \" to \" + end_time + \")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
