{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import math\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='google-10000-english/google-10000-english-no-swears.txt' mode='r' encoding='cp1252'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  words\n",
       "0   the\n",
       "1    of\n",
       "2   and\n",
       "3    to\n",
       "4     a"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = \"google-10000-english/google-10000-english-no-swears.txt\"\n",
    "print(open(filepath))\n",
    "\n",
    "import ast\n",
    "filepath = \"google-10000-english/google-10000-english-no-swears.txt\"\n",
    "words_set = pd.read_csv(filepath, names=['words'])\n",
    "words_set = words_set.iloc[:]\n",
    "words_set = words_set.dropna()\n",
    "words_set = words_set.drop(1820)\n",
    "words_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the optimal frequency to guess words fastest and using the fewest steps\n",
    "#changing frequency through a rotation and seeing the output and making choices based on it\n",
    "#finding effectiveness by taking the Guess Success Ratio (GSR) -> guesses/UNIQUE letters in word (try 'school' to see why)\n",
    "#lowest GSR \"wins\"\n",
    "#three trials per Frequency Model on a set of 500 words randomly selected from the 10,000 word set\n",
    "#first, build one operational model \n",
    "#then, transform key aspects to variables to see how effective things are\n",
    "#finally, test data and wait to see what happens\n",
    "#let's begin!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "raw_mimetype": "text/x-python"
   },
   "outputs": [],
   "source": [
    "def test_runner(slope, intercept): #this function runs the various tests of the program to determine the GSR of the Frequency Model\n",
    "    #UTILITY FUNCTIONS\n",
    "    def init_freq_model(slope, intercept):\n",
    "        #create words_details\n",
    "        words_details = words_set.iloc[:]\n",
    "        word_deet_len = len(words_details)\n",
    "        words_details['word freq'] = np.array([intercept*word_deet_len + slope*i for i in range(word_deet_len)])\n",
    "        words_details['word length'] = np.array([len(words_set.iloc[i][0]) for i in range(word_deet_len)])\n",
    "        words_details.head()\n",
    "        return words_details\n",
    "    \n",
    "    def key_of_max_val(dict_in):\n",
    "        \"\"\"\n",
    "        >>> test_dict = {'a': 1, 'b': 2, 'c':5, 'd': 3}\n",
    "        >>> print(key_of_max_val(test_dict))\n",
    "        c \"\"\"\n",
    "        #this function returns the key that has the highest value in a dictionary\n",
    "        max_val = [key for key in dict_in if dict_in[key] ==  max([dict_in[key] for key in dict_in])  ]\n",
    "        return max_val\n",
    "    \n",
    "    #interval -> at what percent to print\n",
    "    #obj_size -> how big the object is\n",
    "    #curr_pos -> how far through the object calculations are\n",
    "    #addendum -> the string to print after 'n% completed'\n",
    "    def completion_updater(interval, obj_size, curr_pos, addendum):\n",
    "        if curr_pos % (obj_size//interval) == 0 or curr_pos == obj_size:\n",
    "            completion = (curr_pos*100)//obj_size\n",
    "            print(\"{0:3d}% completed\".format(completion), addendum)\n",
    "            \n",
    "    #custom exception for this program \n",
    "    class WordNotInDictionaryError(Exception):\n",
    "        def __init__(self, value):\n",
    "            self.value = value\n",
    "        def __str__(self):\n",
    "            print(\"Uh oh! Looks like you've tried to put in a word that's \" + \n",
    "                  \"not in our dictionary. Double check the spelling just in case, \" + \n",
    "                  \"but keep in mind that our dictionary is limited to only 10,000 words, \" +\n",
    "                  \"so we may just not have that word quite yet!\")\n",
    "            return repr(self.value)\n",
    "        \n",
    "#end utility functions\n",
    "#-------------------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "    #function that handles guessing the word and returns the number of guesses made     \n",
    "    # hangman is the word we're trying to find, need to eventually replace with user input\n",
    "    def guess_word(hangman, blanks=None, possible_words=pd.DataFrame(), guesses=0): \n",
    "\n",
    "        # possible_words: a set of words of length n \n",
    "        # blanks: a set of known letters for the words\n",
    "        # objective: to find a new set of words that meets the requirements outlined in blanks\n",
    "        def get_word_options(possible_words):  \n",
    "            blank_dict = {}\n",
    "            # create a dictionary for blanks that states the value at the index; if none, then nothing is put\n",
    "            for a in range(len(blanks)):\n",
    "                if blanks[a] != \"\":\n",
    "                    blank_dict[a] = blanks[a]\n",
    "            #print(blank_dict)\n",
    "\n",
    "            #see what words meet blanks' requirements\n",
    "            col_list = [\"word\", \"word freq\"]\n",
    "            word_list = []\n",
    "            word_freq_list = []\n",
    "            for i in range(len(possible_words)): # for each word in possible_words\n",
    "                word = possible_words.iloc[i][0]\n",
    "                word_freq = possible_words.iloc[i][1]\n",
    "                meets_req = True\n",
    "                for jndex in blank_dict: # for each index in blank_dict \n",
    "                    if word[jndex] != blank_dict[jndex]:\n",
    "                        meets_req = False\n",
    "                if meets_req:\n",
    "                    word_list.append(word)\n",
    "                    word_freq_list.append(word_freq)\n",
    "            word_ops = pd.DataFrame(data = {\"word\": np.array(word_list), \"word_freq\": np.array(word_freq_list)})\n",
    "            return word_ops\n",
    "\n",
    "        # create a dictionary that has the frequency of each letter from the word_options to determine the optimal guesses \n",
    "        def get_guess(word, word_ops):\n",
    "            assert isinstance(word, list), \"the incoming word must be a list\"\n",
    "            letter_dict = {}\n",
    "            for i in range(len(word_ops)):\n",
    "                curr_word = word_ops.iloc[i][0]\n",
    "                word_freq = word_ops.iloc[i][1]\n",
    "                for j in range(len(curr_word)):\n",
    "                    curr_letter = curr_word[j]\n",
    "                    if letter_dict.get(curr_letter, 0) == 0:\n",
    "                        letter_dict[curr_letter] = 0\n",
    "                    letter_dict[curr_letter] = letter_dict[curr_letter] + word_freq\n",
    "            for letter in blanks:\n",
    "                if letter:\n",
    "                    letter_dict[letter] = -1\n",
    "            return letter_dict\n",
    "\n",
    "        # purpose: to guess a letter for the word\n",
    "        # method: guess the letter with the highest frequency from the dict; if that doesn't work, guess the next highest, recursively.\n",
    "        def make_guess(dict_in):\n",
    "            nonlocal guesses\n",
    "            guesses += 1 #increment the number of guesses thus far made\n",
    "            curr_guess = key_of_max_val(dict_in)[0]\n",
    "            if dict_in[curr_guess] == -1:\n",
    "                raise WordNotInDictionaryError(\"We're unable to determine your word, but here's what we have so far: \" + str(guess_dict))\n",
    "            correct, word = guess_letter(curr_guess, blanks)\n",
    "            if not(correct):\n",
    "                dict_in[curr_guess] = -1\n",
    "                return make_guess(dict_in)\n",
    "            else:\n",
    "                return word\n",
    "\n",
    "        # this method returns whether the guessed letter is in the word, and the thus-filled word after the guess\n",
    "        def guess_letter(letter, word):\n",
    "            in_hangman = False\n",
    "            if letter in hangman:\n",
    "                in_hangman = True\n",
    "                indices = []\n",
    "                for i in range(len(hangman)):\n",
    "                    if letter == hangman[i]:\n",
    "                        indices.append(i)\n",
    "                for i in indices:\n",
    "                    word[i] = letter\n",
    "            return in_hangman, word\n",
    "\n",
    "        #see if the guessed word is the same as the word input to the program by inspecting it letter-by-letter\n",
    "        def test_success(word, hangman):\n",
    "            for i in range(len(hangman)):\n",
    "                if word[i] != hangman[i]:\n",
    "                    return False\n",
    "            return True\n",
    "\n",
    "        #next 4 lines only happen in the first iteration\n",
    "        if not blanks: # this is a baseline for the parts of the word we've guessed so far\n",
    "            blanks = [\"\"]*len(hangman)\n",
    "        if possible_words.empty: #this a baseline for the words that hangman could be\n",
    "            possible_words = words_details[words_details['word length'] == len(blanks)][:]\n",
    "\n",
    "        word_options = get_word_options(possible_words)\n",
    "        guess_dict = get_guess(blanks, word_options)\n",
    "        word = make_guess(guess_dict)\n",
    "        if test_success(word, hangman):\n",
    "            return guesses\n",
    "        else:\n",
    "            return guess_word(hangman, word, word_options, guesses)\n",
    "    \n",
    "    #samples the words_details to get a list of 500 random words to test\n",
    "    def get_random_sample(num_samples=500):\n",
    "        sampled_words_df = words_details.sample(n=num_samples)\n",
    "        print(num_samples, \"words generated to test\")\n",
    "        return [sampled_words_df.iloc[i][0] for i in range(num_samples)]\n",
    "    \n",
    "    #central method code. this does the testing for 500 random words 5 times\n",
    "    start_time = datetime.datetime.now()\n",
    "    print(\"start at\", start_time) #start time\n",
    "    words_details = init_freq_model(slope, intercept)\n",
    "    reruns, sampling_size = 5, 500\n",
    "    gsr_list_onesetting = []\n",
    "    for i in range(1, reruns+1):\n",
    "        gsr_list_onerun = []\n",
    "        rand_word_list = get_random_sample(sampling_size)\n",
    "        rand_word_list_len = len(rand_word_list)\n",
    "        print(\"RUNNING TEST #\" + str(i))\n",
    "        count = 0\n",
    "        for j in range(rand_word_list_len):\n",
    "            completion_updater(10, sampling_size, j, \"(\" + str(datetime.datetime.now()) + \")\") # print the % done and time\n",
    "            word = rand_word_list[j]\n",
    "            word_len = len(word)\n",
    "            guesses = guess_word(word)\n",
    "            gsr = guesses/word_len*100             #MAYBE NEED TO REMOVE THE *100            #MAYBE NEED TO REMOVE THE *100       #MAYBE NEED TO REMOVE THE *100\n",
    "            gsr_list_onerun.append(gsr)\n",
    "        av_gsr_onerun = sum(gsr_list_onerun)/float(len(gsr_list_onerun))\n",
    "        print(\"TEST {0} GSR: {1:7.4} computed in {2:10.5}\".format(i, av_gsr_onerun, str(datetime.datetime.now() - start_time))) \n",
    "        gsr_list_onesetting.append(av_gsr_onerun)\n",
    "    av_gsr_onesetting = sum(gsr_list_onesetting)/float(len(gsr_list_onesetting))\n",
    "    end_time = datetime.datetime.now()\n",
    "    print(\"end at\", end_time) #start time\n",
    "    print(\"TOTAL TIME ELAPSED\", end_time - start_time)\n",
    "    print(\"GSR FOR FREQ MODEL S= \" + str(round(slope, 5)) + \",I=\" + str(round(intercept, 5)) + \": \" + str(round(av_gsr_onesetting, 5)))\n",
    "    print('\\n\\n\\n\\n')\n",
    "    return av_gsr_onesetting\n",
    "        #ALTERNATE CODE (less testing capabilities): gsr_one_test = [guess_word(word)/len(word) for word in rand_word_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning Optimization Procedures!\n",
      "start at 2019-01-15 09:40:47.281852\n",
      "running test 1\n",
      "500 words generated to test\n",
      "  0% completed with test 1 at 2019-01-15 09:40:48.484057\n",
      " 10% completed with test 1 at 2019-01-15 09:41:52.525075\n",
      " 20% completed with test 1 at 2019-01-15 09:42:53.234649\n",
      " 30% completed with test 1 at 2019-01-15 09:43:49.218841\n",
      " 40% completed with test 1 at 2019-01-15 09:44:41.192878\n",
      " 50% completed with test 1 at 2019-01-15 09:45:38.828644\n",
      " 60% completed with test 1 at 2019-01-15 09:46:37.577943\n",
      " 70% completed with test 1 at 2019-01-15 09:47:36.848104\n",
      " 80% completed with test 1 at 2019-01-15 09:48:36.823172\n",
      " 90% completed with test 1 at 2019-01-15 09:49:27.064052\n",
      " 99% completed with test 1 at 2019-01-15 09:50:24.244496\n",
      "test gsr: 2.1e+02 computed in 0:09:     \n",
      "running test 2\n",
      "500 words generated to test\n",
      "  0% completed with test 2 at 2019-01-15 09:50:25.776320\n",
      " 10% completed with test 2 at 2019-01-15 09:51:18.314526\n",
      " 20% completed with test 2 at 2019-01-15 09:52:17.901256\n",
      " 30% completed with test 2 at 2019-01-15 09:53:10.759372\n",
      " 40% completed with test 2 at 2019-01-15 09:54:06.718756\n",
      " 50% completed with test 2 at 2019-01-15 09:56:11.190170\n",
      " 60% completed with test 2 at 2019-01-15 09:57:57.160369\n",
      " 70% completed with test 2 at 2019-01-15 09:59:48.442741\n",
      " 80% completed with test 2 at 2019-01-15 10:01:22.722598\n",
      " 90% completed with test 2 at 2019-01-15 10:02:22.791398\n",
      " 99% completed with test 2 at 2019-01-15 10:03:15.349428\n",
      "test gsr: 1.9e+02 computed in 0:22:     \n",
      "running test 3\n",
      "500 words generated to test\n",
      "  0% completed with test 3 at 2019-01-15 10:03:16.802607\n",
      " 10% completed with test 3 at 2019-01-15 10:04:07.835791\n",
      " 20% completed with test 3 at 2019-01-15 10:05:10.774042\n",
      " 30% completed with test 3 at 2019-01-15 10:06:10.077137\n",
      " 40% completed with test 3 at 2019-01-15 10:07:10.423683\n",
      " 50% completed with test 3 at 2019-01-15 10:08:08.716174\n",
      " 60% completed with test 3 at 2019-01-15 10:09:01.220699\n",
      " 70% completed with test 3 at 2019-01-15 10:09:57.225418\n",
      " 80% completed with test 3 at 2019-01-15 10:10:49.882943\n",
      " 90% completed with test 3 at 2019-01-15 10:11:36.251768\n",
      " 99% completed with test 3 at 2019-01-15 10:12:30.131384\n",
      "test gsr: 2.3e+02 computed in 0:31:     \n",
      "running test 4\n",
      "500 words generated to test\n",
      "  0% completed with test 4 at 2019-01-15 10:12:31.510697\n",
      " 10% completed with test 4 at 2019-01-15 10:13:24.409146\n",
      " 20% completed with test 4 at 2019-01-15 10:14:22.087576\n",
      " 30% completed with test 4 at 2019-01-15 10:15:26.779016\n",
      " 40% completed with test 4 at 2019-01-15 10:16:47.017697\n",
      " 50% completed with test 4 at 2019-01-15 10:18:00.504036\n",
      " 60% completed with test 4 at 2019-01-15 10:19:02.454708\n",
      " 70% completed with test 4 at 2019-01-15 10:19:46.577238\n",
      " 80% completed with test 4 at 2019-01-15 10:20:52.453234\n",
      " 90% completed with test 4 at 2019-01-15 10:21:42.023154\n",
      " 99% completed with test 4 at 2019-01-15 10:24:24.902889\n",
      "test gsr: 2.1e+02 computed in 0:43:     \n",
      "running test 5\n",
      "500 words generated to test\n",
      "  0% completed with test 5 at 2019-01-15 10:24:26.046827\n",
      " 10% completed with test 5 at 2019-01-15 10:25:19.593008\n",
      " 20% completed with test 5 at 2019-01-15 10:26:06.983515\n",
      " 30% completed with test 5 at 2019-01-15 10:27:03.118896\n",
      " 40% completed with test 5 at 2019-01-15 10:28:01.715698\n",
      " 50% completed with test 5 at 2019-01-15 10:29:09.702698\n",
      " 60% completed with test 5 at 2019-01-15 10:30:04.738379\n",
      " 70% completed with test 5 at 2019-01-15 10:30:54.999583\n",
      " 80% completed with test 5 at 2019-01-15 10:31:37.908948\n",
      " 90% completed with test 5 at 2019-01-15 10:32:22.879854\n",
      " 99% completed with test 5 at 2019-01-15 10:33:03.904980\n",
      "test gsr: 2.2e+02 computed in 0:52:     \n",
      "end at 2019-01-15 10:33:04.454832\n",
      "total time elapsed 0:52:17.172980\n",
      "overall gsr for Freq Model: \n",
      "\n",
      "new base Slope: -1  Intercept: 1  GSR: 212.71418\n",
      "start at 2019-01-15 10:33:04.470501\n",
      "running test 1\n",
      "500 words generated to test\n",
      "  0% completed with test 1 at 2019-01-15 10:33:05.424428\n",
      " 10% completed with test 1 at 2019-01-15 10:33:49.581542\n",
      " 20% completed with test 1 at 2019-01-15 10:34:35.842783\n",
      " 30% completed with test 1 at 2019-01-15 10:35:24.889957\n",
      " 40% completed with test 1 at 2019-01-15 10:36:10.662103\n",
      " 50% completed with test 1 at 2019-01-15 10:36:56.018724\n",
      " 60% completed with test 1 at 2019-01-15 10:37:48.039965\n",
      " 70% completed with test 1 at 2019-01-15 10:38:35.827094\n",
      " 80% completed with test 1 at 2019-01-15 10:39:34.931723\n",
      " 90% completed with test 1 at 2019-01-15 10:40:24.347002\n",
      " 99% completed with test 1 at 2019-01-15 10:41:14.986787\n",
      "test gsr: 2.2e+02 computed in 0:08:     \n",
      "running test 2\n",
      "500 words generated to test\n",
      "  0% completed with test 2 at 2019-01-15 10:41:17.518094\n",
      " 10% completed with test 2 at 2019-01-15 10:42:13.870185\n",
      " 20% completed with test 2 at 2019-01-15 10:43:09.502891\n",
      " 30% completed with test 2 at 2019-01-15 10:44:12.291394\n",
      " 40% completed with test 2 at 2019-01-15 10:45:06.506594\n",
      " 50% completed with test 2 at 2019-01-15 10:45:57.274032\n",
      " 60% completed with test 2 at 2019-01-15 10:46:50.346035\n",
      " 70% completed with test 2 at 2019-01-15 10:47:56.410879\n",
      " 80% completed with test 2 at 2019-01-15 10:48:54.578041\n",
      " 90% completed with test 2 at 2019-01-15 10:49:54.424397\n",
      " 99% completed with test 2 at 2019-01-15 10:50:57.211770\n",
      "test gsr:  2e+02 computed in 0:17:     \n",
      "running test 3\n",
      "500 words generated to test\n",
      "  0% completed with test 3 at 2019-01-15 10:50:57.653585\n",
      " 10% completed with test 3 at 2019-01-15 10:51:52.879581\n",
      " 20% completed with test 3 at 2019-01-15 10:52:42.843876\n",
      " 30% completed with test 3 at 2019-01-15 10:53:30.654952\n",
      " 40% completed with test 3 at 2019-01-15 10:54:32.067896\n",
      " 50% completed with test 3 at 2019-01-15 10:55:39.880479\n",
      " 60% completed with test 3 at 2019-01-15 10:56:35.168274\n",
      " 70% completed with test 3 at 2019-01-15 10:57:34.041291\n",
      " 80% completed with test 3 at 2019-01-15 10:58:34.372574\n",
      " 90% completed with test 3 at 2019-01-15 10:59:36.840110\n",
      " 99% completed with test 3 at 2019-01-15 11:00:59.644578\n",
      "test gsr: 2.1e+02 computed in 0:27:     \n",
      "running test 4\n",
      "500 words generated to test\n",
      "  0% completed with test 4 at 2019-01-15 11:01:00.364896\n",
      " 10% completed with test 4 at 2019-01-15 11:01:57.537294\n",
      " 20% completed with test 4 at 2019-01-15 11:02:57.552331\n",
      " 30% completed with test 4 at 2019-01-15 11:04:24.577656\n",
      " 40% completed with test 4 at 2019-01-15 11:05:49.171787\n",
      " 50% completed with test 4 at 2019-01-15 11:06:45.332521\n",
      " 60% completed with test 4 at 2019-01-15 11:07:33.632157\n",
      " 70% completed with test 4 at 2019-01-15 11:08:23.688005\n",
      " 80% completed with test 4 at 2019-01-15 11:09:15.497672\n",
      " 90% completed with test 4 at 2019-01-15 11:10:05.463684\n",
      " 99% completed with test 4 at 2019-01-15 11:10:50.975836\n",
      "test gsr: 1.9e+02 computed in 0:37:     \n",
      "running test 5\n",
      "500 words generated to test\n",
      "  0% completed with test 5 at 2019-01-15 11:10:51.646040\n",
      " 10% completed with test 5 at 2019-01-15 11:11:38.063511\n",
      " 20% completed with test 5 at 2019-01-15 11:12:25.495713\n",
      " 30% completed with test 5 at 2019-01-15 11:13:13.894791\n",
      " 40% completed with test 5 at 2019-01-15 11:13:58.480181\n",
      " 50% completed with test 5 at 2019-01-15 11:14:49.372309\n",
      " 60% completed with test 5 at 2019-01-15 11:15:33.795348\n",
      " 70% completed with test 5 at 2019-01-15 11:16:23.605374\n",
      " 80% completed with test 5 at 2019-01-15 11:17:11.134344\n",
      " 90% completed with test 5 at 2019-01-15 11:17:53.250629\n",
      " 99% completed with test 5 at 2019-01-15 11:18:36.849407\n",
      "test gsr:  2e+02 computed in 0:45:     \n",
      "end at 2019-01-15 11:18:37.628431\n",
      "total time elapsed 0:45:33.157930\n",
      "overall gsr for Freq Model: \n",
      "start at 2019-01-15 11:18:37.650563\n",
      "running test 1\n",
      "500 words generated to test\n",
      "  0% completed with test 1 at 2019-01-15 11:18:38.583695\n",
      " 10% completed with test 1 at 2019-01-15 11:19:27.326496\n",
      " 20% completed with test 1 at 2019-01-15 11:20:14.168555\n",
      " 30% completed with test 1 at 2019-01-15 11:20:56.680268\n",
      " 40% completed with test 1 at 2019-01-15 11:21:40.684685\n",
      " 50% completed with test 1 at 2019-01-15 11:22:27.219774\n",
      " 60% completed with test 1 at 2019-01-15 11:23:17.253805\n",
      " 70% completed with test 1 at 2019-01-15 11:24:03.631231\n",
      " 80% completed with test 1 at 2019-01-15 11:24:50.162285\n",
      " 90% completed with test 1 at 2019-01-15 11:25:38.246204\n",
      " 99% completed with test 1 at 2019-01-15 11:26:24.497924\n",
      "test gsr:  2e+02 computed in 0:07:     \n",
      "running test 2\n",
      "500 words generated to test\n",
      "  0% completed with test 2 at 2019-01-15 11:26:25.508219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 10% completed with test 2 at 2019-01-15 11:27:10.423567\n",
      " 20% completed with test 2 at 2019-01-15 11:27:57.957336\n",
      " 30% completed with test 2 at 2019-01-15 11:28:42.462693\n",
      " 40% completed with test 2 at 2019-01-15 11:29:24.757455\n",
      " 50% completed with test 2 at 2019-01-15 11:30:10.803280\n",
      " 60% completed with test 2 at 2019-01-15 11:30:56.658001\n",
      " 70% completed with test 2 at 2019-01-15 11:31:46.220431\n",
      " 80% completed with test 2 at 2019-01-15 11:32:34.457871\n",
      " 90% completed with test 2 at 2019-01-15 11:33:22.926729\n",
      " 99% completed with test 2 at 2019-01-15 11:34:04.615651\n",
      "test gsr: 1.9e+02 computed in 0:15:     \n",
      "running test 3\n",
      "500 words generated to test\n",
      "  0% completed with test 3 at 2019-01-15 11:34:05.665277\n",
      " 10% completed with test 3 at 2019-01-15 11:34:47.865955\n",
      " 20% completed with test 3 at 2019-01-15 11:35:34.213316\n",
      " 30% completed with test 3 at 2019-01-15 11:36:20.321985\n",
      " 40% completed with test 3 at 2019-01-15 11:37:06.091874\n",
      " 50% completed with test 3 at 2019-01-15 11:37:53.783580\n",
      " 60% completed with test 3 at 2019-01-15 11:38:41.846360\n",
      " 70% completed with test 3 at 2019-01-15 11:39:25.633514\n",
      " 80% completed with test 3 at 2019-01-15 11:40:13.749985\n",
      " 90% completed with test 3 at 2019-01-15 11:41:00.633541\n",
      " 99% completed with test 3 at 2019-01-15 11:41:43.592686\n",
      "test gsr: 2.1e+02 computed in 0:23:     \n",
      "running test 4\n",
      "500 words generated to test\n",
      "  0% completed with test 4 at 2019-01-15 11:41:44.178174\n",
      " 10% completed with test 4 at 2019-01-15 11:42:30.735990\n",
      " 20% completed with test 4 at 2019-01-15 11:43:17.568087\n",
      " 30% completed with test 4 at 2019-01-15 11:44:06.651461\n",
      " 40% completed with test 4 at 2019-01-15 11:44:55.622147\n",
      " 50% completed with test 4 at 2019-01-15 11:45:42.126559\n",
      " 60% completed with test 4 at 2019-01-15 11:46:31.284832\n",
      " 70% completed with test 4 at 2019-01-15 11:47:17.784139\n",
      " 80% completed with test 4 at 2019-01-15 11:48:04.049600\n",
      " 90% completed with test 4 at 2019-01-15 11:48:49.808341\n",
      " 99% completed with test 4 at 2019-01-15 11:49:39.526034\n",
      "test gsr:  2e+02 computed in 0:31:     \n",
      "running test 5\n",
      "500 words generated to test\n",
      "  0% completed with test 5 at 2019-01-15 11:49:41.029999\n",
      " 10% completed with test 5 at 2019-01-15 11:50:31.094530\n",
      " 20% completed with test 5 at 2019-01-15 11:51:17.580545\n",
      " 30% completed with test 5 at 2019-01-15 11:52:01.171511\n",
      " 40% completed with test 5 at 2019-01-15 11:52:47.956435\n",
      " 50% completed with test 5 at 2019-01-15 11:53:35.273903\n",
      " 60% completed with test 5 at 2019-01-15 11:54:20.661682\n",
      " 70% completed with test 5 at 2019-01-15 11:55:16.386424\n",
      " 80% completed with test 5 at 2019-01-15 11:56:01.649513\n",
      " 90% completed with test 5 at 2019-01-15 11:56:49.656037\n",
      " 99% completed with test 5 at 2019-01-15 11:57:35.507263\n",
      "test gsr: 1.9e+02 computed in 0:38:     \n",
      "end at 2019-01-15 11:57:36.443588\n",
      "total time elapsed 0:38:58.793025\n",
      "overall gsr for Freq Model: \n",
      "start at 2019-01-15 11:57:36.459260\n",
      "running test 1\n",
      "500 words generated to test\n",
      "  0% completed with test 1 at 2019-01-15 11:57:37.349001\n",
      " 10% completed with test 1 at 2019-01-15 11:58:24.936116\n",
      " 20% completed with test 1 at 2019-01-15 11:59:09.540933\n",
      " 30% completed with test 1 at 2019-01-15 11:59:57.745153\n",
      " 40% completed with test 1 at 2019-01-15 12:00:40.300852\n",
      " 50% completed with test 1 at 2019-01-15 12:01:28.490105\n",
      " 60% completed with test 1 at 2019-01-15 12:02:15.709924\n",
      " 70% completed with test 1 at 2019-01-15 12:03:01.911206\n",
      " 80% completed with test 1 at 2019-01-15 12:03:49.414533\n",
      " 90% completed with test 1 at 2019-01-15 12:04:36.860724\n",
      " 99% completed with test 1 at 2019-01-15 12:05:24.633403\n",
      "test gsr: 1.9e+02 computed in 0:07:     \n",
      "running test 2\n",
      "500 words generated to test\n",
      "  0% completed with test 2 at 2019-01-15 12:05:25.986235\n",
      " 10% completed with test 2 at 2019-01-15 12:06:11.074078\n",
      " 20% completed with test 2 at 2019-01-15 12:06:59.013269\n",
      " 30% completed with test 2 at 2019-01-15 12:07:49.311232\n",
      " 40% completed with test 2 at 2019-01-15 12:08:39.034242\n",
      " 50% completed with test 2 at 2019-01-15 12:09:27.725262\n",
      " 60% completed with test 2 at 2019-01-15 12:10:15.590661\n",
      " 70% completed with test 2 at 2019-01-15 12:11:05.471413\n",
      " 80% completed with test 2 at 2019-01-15 12:11:54.895367\n",
      " 90% completed with test 2 at 2019-01-15 12:12:39.229994\n",
      " 99% completed with test 2 at 2019-01-15 12:13:25.444284\n",
      "test gsr:  2e+02 computed in 0:15:     \n",
      "running test 3\n",
      "500 words generated to test\n",
      "  0% completed with test 3 at 2019-01-15 12:13:25.513277\n",
      " 10% completed with test 3 at 2019-01-15 12:14:09.754706\n",
      " 20% completed with test 3 at 2019-01-15 12:14:54.399271\n",
      " 30% completed with test 3 at 2019-01-15 12:15:45.646384\n",
      " 40% completed with test 3 at 2019-01-15 12:16:31.771857\n",
      " 50% completed with test 3 at 2019-01-15 12:17:20.710666\n",
      " 60% completed with test 3 at 2019-01-15 12:18:04.137529\n",
      " 70% completed with test 3 at 2019-01-15 12:18:50.142913\n",
      " 80% completed with test 3 at 2019-01-15 12:19:32.477576\n",
      " 90% completed with test 3 at 2019-01-15 12:20:18.732080\n",
      " 99% completed with test 3 at 2019-01-15 12:21:01.462002\n",
      "test gsr:  2e+02 computed in 0:23:     \n",
      "running test 4\n",
      "500 words generated to test\n",
      "  0% completed with test 4 at 2019-01-15 12:21:02.750474\n",
      " 10% completed with test 4 at 2019-01-15 12:21:45.747632\n",
      " 20% completed with test 4 at 2019-01-15 12:22:32.869086\n",
      " 30% completed with test 4 at 2019-01-15 12:23:15.379062\n",
      " 40% completed with test 4 at 2019-01-15 12:23:58.295789\n",
      " 50% completed with test 4 at 2019-01-15 12:24:41.933583\n",
      " 60% completed with test 4 at 2019-01-15 12:25:31.052841\n",
      " 70% completed with test 4 at 2019-01-15 12:26:13.308759\n",
      " 80% completed with test 4 at 2019-01-15 12:26:59.649992\n",
      " 90% completed with test 4 at 2019-01-15 12:27:50.298846\n",
      " 99% completed with test 4 at 2019-01-15 12:28:33.868140\n",
      "test gsr: 2.1e+02 computed in 0:30:     \n",
      "running test 5\n",
      "500 words generated to test\n",
      "  0% completed with test 5 at 2019-01-15 12:28:34.884456\n",
      " 10% completed with test 5 at 2019-01-15 12:29:17.590994\n",
      " 20% completed with test 5 at 2019-01-15 12:30:06.714618\n",
      " 30% completed with test 5 at 2019-01-15 12:30:51.159451\n",
      " 40% completed with test 5 at 2019-01-15 12:31:38.263544\n",
      " 50% completed with test 5 at 2019-01-15 12:32:27.820865\n",
      " 60% completed with test 5 at 2019-01-15 12:33:12.564891\n",
      " 70% completed with test 5 at 2019-01-15 12:34:02.058163\n",
      " 80% completed with test 5 at 2019-01-15 12:34:52.039691\n",
      " 90% completed with test 5 at 2019-01-15 12:35:43.112906\n",
      " 99% completed with test 5 at 2019-01-15 12:36:26.196928\n",
      "test gsr: 2.1e+02 computed in 0:38:     \n",
      "end at 2019-01-15 12:36:27.327551\n",
      "total time elapsed 0:38:50.868291\n",
      "overall gsr for Freq Model: \n",
      "\n",
      "new base Slope: 9.25192  Intercept: 15.96181  GSR: 200.6765\n",
      "start at 2019-01-15 12:36:27.327551\n",
      "running test 1\n",
      "500 words generated to test\n",
      "  0% completed with test 1 at 2019-01-15 12:36:28.212288\n",
      " 10% completed with test 1 at 2019-01-15 12:37:12.931185\n",
      " 20% completed with test 1 at 2019-01-15 12:37:56.711435\n",
      " 30% completed with test 1 at 2019-01-15 12:38:43.300609\n",
      " 40% completed with test 1 at 2019-01-15 12:39:29.545401\n",
      " 50% completed with test 1 at 2019-01-15 12:40:11.511879\n",
      " 60% completed with test 1 at 2019-01-15 12:40:57.986238\n",
      " 70% completed with test 1 at 2019-01-15 12:41:44.504014\n",
      " 80% completed with test 1 at 2019-01-15 12:42:28.946828\n",
      " 90% completed with test 1 at 2019-01-15 12:43:15.532815\n",
      " 99% completed with test 1 at 2019-01-15 12:44:02.860888\n",
      "test gsr: 2.1e+02 computed in 0:07:     \n",
      "running test 2\n",
      "500 words generated to test\n",
      "  0% completed with test 2 at 2019-01-15 12:44:03.262182\n",
      " 10% completed with test 2 at 2019-01-15 12:44:48.143435\n",
      " 20% completed with test 2 at 2019-01-15 12:45:38.165115\n",
      " 30% completed with test 2 at 2019-01-15 12:46:23.744689\n",
      " 40% completed with test 2 at 2019-01-15 12:47:12.997547\n",
      " 50% completed with test 2 at 2019-01-15 12:48:06.380180\n",
      " 60% completed with test 2 at 2019-01-15 12:48:50.155412\n",
      " 70% completed with test 2 at 2019-01-15 12:49:34.338834\n",
      " 80% completed with test 2 at 2019-01-15 12:50:17.545893\n",
      " 90% completed with test 2 at 2019-01-15 12:51:07.713747\n",
      " 99% completed with test 2 at 2019-01-15 12:51:53.884890\n",
      "test gsr:  2e+02 computed in 0:15:     \n",
      "running test 3\n",
      "500 words generated to test\n",
      "  0% completed with test 3 at 2019-01-15 12:51:55.389126\n",
      " 10% completed with test 3 at 2019-01-15 12:52:40.995282\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20% completed with test 3 at 2019-01-15 12:53:30.771396\n",
      " 30% completed with test 3 at 2019-01-15 12:54:19.338455\n",
      " 40% completed with test 3 at 2019-01-15 12:55:07.109853\n",
      " 50% completed with test 3 at 2019-01-15 12:55:48.948166\n",
      " 60% completed with test 3 at 2019-01-15 12:56:35.934081\n",
      " 70% completed with test 3 at 2019-01-15 12:57:25.251790\n",
      " 80% completed with test 3 at 2019-01-15 12:58:13.709700\n",
      " 90% completed with test 3 at 2019-01-15 12:59:02.265777\n",
      " 99% completed with test 3 at 2019-01-15 12:59:43.365045\n",
      "test gsr:  2e+02 computed in 0:23:     \n",
      "running test 4\n",
      "500 words generated to test\n",
      "  0% completed with test 4 at 2019-01-15 12:59:44.668122\n",
      " 10% completed with test 4 at 2019-01-15 13:00:33.098122\n",
      " 20% completed with test 4 at 2019-01-15 13:01:18.987205\n",
      " 30% completed with test 4 at 2019-01-15 13:02:05.344655\n",
      " 40% completed with test 4 at 2019-01-15 13:02:55.431595\n",
      " 50% completed with test 4 at 2019-01-15 13:03:51.307572\n",
      " 60% completed with test 4 at 2019-01-15 13:04:48.330968\n",
      " 70% completed with test 4 at 2019-01-15 13:05:45.988642\n",
      " 80% completed with test 4 at 2019-01-15 13:06:43.598191\n",
      " 90% completed with test 4 at 2019-01-15 13:07:45.972864\n",
      " 99% completed with test 4 at 2019-01-15 13:08:41.707117\n",
      "test gsr: 1.9e+02 computed in 0:32:     \n",
      "running test 5\n",
      "500 words generated to test\n",
      "  0% completed with test 5 at 2019-01-15 13:08:42.257240\n",
      " 10% completed with test 5 at 2019-01-15 13:09:31.876506\n",
      " 20% completed with test 5 at 2019-01-15 13:10:28.266410\n",
      " 30% completed with test 5 at 2019-01-15 13:11:24.641985\n",
      " 40% completed with test 5 at 2019-01-15 13:13:10.227437\n",
      " 50% completed with test 5 at 2019-01-15 13:14:06.552700\n",
      " 60% completed with test 5 at 2019-01-15 13:15:20.477717\n",
      " 70% completed with test 5 at 2019-01-15 13:16:25.649418\n",
      " 80% completed with test 5 at 2019-01-15 13:17:25.353231\n",
      " 90% completed with test 5 at 2019-01-15 13:18:32.042577\n",
      " 99% completed with test 5 at 2019-01-15 13:19:29.606319\n",
      "test gsr: 1.9e+02 computed in 0:43:     \n",
      "end at 2019-01-15 13:19:31.060417\n",
      "total time elapsed 0:43:03.732866\n",
      "overall gsr for Freq Model: \n",
      "start at 2019-01-15 13:19:31.095433\n",
      "running test 1\n",
      "500 words generated to test\n",
      "  0% completed with test 1 at 2019-01-15 13:19:32.047849\n",
      " 10% completed with test 1 at 2019-01-15 13:20:26.370265\n",
      " 20% completed with test 1 at 2019-01-15 13:21:21.865582\n",
      " 30% completed with test 1 at 2019-01-15 13:22:12.476747\n",
      " 40% completed with test 1 at 2019-01-15 13:23:14.379843\n",
      " 50% completed with test 1 at 2019-01-15 13:24:11.066561\n",
      " 60% completed with test 1 at 2019-01-15 13:24:59.662063\n",
      " 70% completed with test 1 at 2019-01-15 13:26:04.502879\n",
      " 80% completed with test 1 at 2019-01-15 13:27:05.641113\n",
      " 90% completed with test 1 at 2019-01-15 13:54:41.940844\n",
      " 99% completed with test 1 at 2019-01-15 18:07:21.698331\n",
      "test gsr: 2.1e+02 computed in 4:47:     \n",
      "running test 2\n",
      "500 words generated to test\n",
      "  0% completed with test 2 at 2019-01-15 18:07:23.107526\n",
      " 10% completed with test 2 at 2019-01-15 18:08:12.878344\n",
      " 20% completed with test 2 at 2019-01-15 18:09:00.667466\n",
      " 30% completed with test 2 at 2019-01-15 18:09:47.933016\n",
      " 40% completed with test 2 at 2019-01-15 18:10:38.142669\n",
      " 50% completed with test 2 at 2019-01-15 18:11:23.427459\n",
      " 60% completed with test 2 at 2019-01-15 18:12:10.755814\n",
      " 70% completed with test 2 at 2019-01-15 18:12:54.150695\n",
      " 80% completed with test 2 at 2019-01-15 18:13:44.627664\n",
      " 90% completed with test 2 at 2019-01-15 18:14:44.368038\n",
      " 99% completed with test 2 at 2019-01-15 18:15:39.632976\n",
      "test gsr: 1.9e+02 computed in 4:56:     \n",
      "running test 3\n",
      "500 words generated to test\n",
      "  0% completed with test 3 at 2019-01-15 18:15:40.179258\n",
      " 10% completed with test 3 at 2019-01-15 18:16:39.602953\n",
      " 20% completed with test 3 at 2019-01-15 18:17:30.942405\n",
      " 30% completed with test 3 at 2019-01-15 18:18:21.492756\n",
      " 40% completed with test 3 at 2019-01-15 18:19:11.348067\n",
      " 50% completed with test 3 at 2019-01-15 18:19:56.299694\n",
      " 60% completed with test 3 at 2019-01-15 18:20:49.520227\n",
      " 70% completed with test 3 at 2019-01-15 18:21:48.451892\n",
      " 80% completed with test 3 at 2019-01-15 18:22:46.957521\n",
      " 90% completed with test 3 at 2019-01-15 18:23:44.945593\n",
      " 99% completed with test 3 at 2019-01-15 18:25:37.579531\n",
      "test gsr: 2.1e+02 computed in 5:06:     \n",
      "running test 4\n",
      "500 words generated to test\n",
      "  0% completed with test 4 at 2019-01-15 18:25:38.335356\n",
      " 10% completed with test 4 at 2019-01-15 18:26:48.821382\n",
      " 20% completed with test 4 at 2019-01-15 18:28:02.761174\n",
      " 30% completed with test 4 at 2019-01-15 18:29:20.795424\n",
      " 40% completed with test 4 at 2019-01-15 18:30:21.847863\n",
      " 50% completed with test 4 at 2019-01-15 18:32:36.352816\n",
      " 60% completed with test 4 at 2019-01-15 18:34:43.374596\n",
      " 70% completed with test 4 at 2019-01-15 18:36:45.867093\n",
      " 80% completed with test 4 at 2019-01-15 18:38:56.967957\n",
      " 90% completed with test 4 at 2019-01-16 05:00:37.066573\n",
      " 99% completed with test 4 at 2019-01-16 05:01:24.839258\n",
      "test gsr: 1.8e+02 computed in 15:41     \n",
      "running test 5\n",
      "500 words generated to test\n",
      "  0% completed with test 5 at 2019-01-16 05:01:26.715239\n",
      " 10% completed with test 5 at 2019-01-16 05:02:30.898978\n",
      " 20% completed with test 5 at 2019-01-16 05:03:26.241830\n",
      " 30% completed with test 5 at 2019-01-16 05:04:12.824972\n",
      " 40% completed with test 5 at 2019-01-16 05:05:11.983624\n",
      " 50% completed with test 5 at 2019-01-16 05:05:59.270274\n",
      " 60% completed with test 5 at 2019-01-16 05:06:50.272723\n",
      " 70% completed with test 5 at 2019-01-16 05:07:43.092365\n",
      " 80% completed with test 5 at 2019-01-16 05:08:33.274185\n",
      " 90% completed with test 5 at 2019-01-16 05:09:27.185431\n",
      " 99% completed with test 5 at 2019-01-16 05:10:18.721099\n",
      "test gsr:  2e+02 computed in 15:50     \n",
      "end at 2019-01-16 05:10:19.695531\n",
      "total time elapsed 15:50:48.600098\n",
      "overall gsr for Freq Model: \n",
      "start at 2019-01-16 05:10:19.710691\n",
      "running test 1\n",
      "500 words generated to test\n",
      "  0% completed with test 1 at 2019-01-16 05:10:20.646044\n",
      " 10% completed with test 1 at 2019-01-16 05:11:07.341980\n",
      " 20% completed with test 1 at 2019-01-16 05:11:54.731776\n",
      " 30% completed with test 1 at 2019-01-16 05:12:46.513719\n",
      " 40% completed with test 1 at 2019-01-16 05:13:37.498724\n",
      " 50% completed with test 1 at 2019-01-16 05:14:28.922872\n",
      " 60% completed with test 1 at 2019-01-16 05:15:21.787405\n",
      " 70% completed with test 1 at 2019-01-16 05:16:16.350804\n",
      " 80% completed with test 1 at 2019-01-16 05:17:08.311253\n",
      " 90% completed with test 1 at 2019-01-16 05:18:09.771665\n",
      " 99% completed with test 1 at 2019-01-16 05:19:39.270642\n",
      "test gsr:  2e+02 computed in 0:09:     \n",
      "running test 2\n",
      "500 words generated to test\n",
      "  0% completed with test 2 at 2019-01-16 05:19:40.551251\n",
      " 10% completed with test 2 at 2019-01-16 05:21:25.349052\n",
      " 20% completed with test 2 at 2019-01-16 05:22:58.038013\n",
      " 30% completed with test 2 at 2019-01-16 05:23:58.768472\n",
      " 40% completed with test 2 at 2019-01-16 05:25:40.991458\n",
      " 50% completed with test 2 at 2019-01-16 05:26:46.532495\n",
      " 60% completed with test 2 at 2019-01-16 05:27:55.658853\n",
      " 70% completed with test 2 at 2019-01-16 05:29:02.729039\n",
      " 80% completed with test 2 at 2019-01-16 05:30:19.253696\n",
      " 90% completed with test 2 at 2019-01-16 05:31:13.052738\n",
      " 99% completed with test 2 at 2019-01-16 05:32:04.769349\n",
      "test gsr: 1.9e+02 computed in 0:21:     \n",
      "running test 3\n",
      "500 words generated to test\n",
      "  0% completed with test 3 at 2019-01-16 05:32:06.151650\n",
      " 10% completed with test 3 at 2019-01-16 05:33:07.718863\n",
      " 20% completed with test 3 at 2019-01-16 05:34:01.383299\n",
      " 30% completed with test 3 at 2019-01-16 05:35:22.667521\n",
      " 40% completed with test 3 at 2019-01-16 05:36:48.400040\n",
      " 50% completed with test 3 at 2019-01-16 05:37:40.978913\n",
      " 60% completed with test 3 at 2019-01-16 05:38:51.973834\n",
      " 70% completed with test 3 at 2019-01-16 05:40:00.578257\n",
      " 80% completed with test 3 at 2019-01-16 05:41:38.336702\n",
      " 90% completed with test 3 at 2019-01-16 05:42:53.862249\n",
      " 99% completed with test 3 at 2019-01-16 05:44:30.389992\n",
      "test gsr: 1.9e+02 computed in 0:34:     \n",
      "running test 4\n",
      "500 words generated to test\n",
      "  0% completed with test 4 at 2019-01-16 05:44:32.269958\n"
     ]
    }
   ],
   "source": [
    "class XYZ:\n",
    "    gsr = ()\n",
    "    def __init__(self, x, y):\n",
    "        self.slope = x \n",
    "        self.intercept = y\n",
    "    \n",
    "    def get_gsr(self):\n",
    "        if not self.has_gsr():\n",
    "            #print(\"testing for gsr!\")\n",
    "            gsr = test_values(self.slope, self.intercept)\n",
    "            self.update_gsr(gsr)\n",
    "        \n",
    "    def update_gsr(self, gsr):\n",
    "        self.gsr = gsr\n",
    "        #print(\"gsr set to:\", gsr)\n",
    "        \n",
    "    def has_gsr(self):\n",
    "        return self.gsr != ()\n",
    "    \n",
    "    def del_gsr(self, base):\n",
    "        if not(self.has_gsr()): #when self missing gsr\n",
    "            #print(\"getting self gsr!\") \n",
    "            self.get_gsr()\n",
    "        if not(base.has_gsr()): #when other missing gsr\n",
    "            #print(\"getting other gsr!\")\n",
    "            base.get_gsr()\n",
    "        #when both have gsr, return the difference between other and self\n",
    "        #print(\"gsr difference:\", base.gsr - self.gsr, \" = base.gsr (\" + str(base.gsr) + \") - self.gsr (\" + str(self.gsr) + \")\")\n",
    "        return base.gsr - self.gsr\n",
    "            \n",
    "    def del_pos_sum(self, base):\n",
    "        #print(\"getting positional sum\")\n",
    "        #print(\"intercepts:\", self.intercept, base.intercept)\n",
    "        #print(\"slope:\", self.slope, base.slope)\n",
    "        return (self.intercept - base.intercept) + (self.slope - base.slope)\n",
    "    \n",
    "    def del_pos_vector(self, base):\n",
    "        #print(\"creating positional difference vector!\")\n",
    "        #print([base.intercept - self.intercept, base.slope - self.slope])\n",
    "        return [base.slope - self.slope, base.intercept - self.intercept]\n",
    "    \n",
    "    def differential(self, base):\n",
    "        del_gsr = self.del_gsr(base)\n",
    "        del_pos = self.del_pos_sum(base)\n",
    "        #print(\"del_gsr:\", del_gsr, \"del_pos\", del_pos)\n",
    "        diff = del_gsr/del_pos\n",
    "        #print(\"gsr differential:\", diff)\n",
    "        return diff\n",
    "        \n",
    "    def delta_vector(self, p1, p2):\n",
    "        vector1 = self.del_pos_vector(p1)\n",
    "        #print(\"vector for b\", vector1)\n",
    "        vector2 = self.del_pos_vector(p2)\n",
    "        #print(\"vector for c\", vector2)\n",
    "        differential1 = p1.differential(self)\n",
    "        #print(\"differential for b\", differential1)\n",
    "        differential2 = p2.differential(self)\n",
    "        #print(\"differential for c\", differential2)\n",
    "        vector = [0, 0]\n",
    "        vector[0] = round(differential1*vector1[0] + differential2*vector2[0], 5)\n",
    "        vector[1] = round(differential1*vector1[1] + differential2*vector2[1], 5)\n",
    "        #print(\"change vector:\", vector)\n",
    "        return vector\n",
    "\n",
    "    #create secondary and tertiary points\n",
    "    def get_points(self): # self is the starting point\n",
    "        #change_factor = math.sqrt(abs(self.gsr-3))\n",
    "        change_factor = 1/(0.1 + 4*pow(0.7, self.gsr))-0.244 \n",
    "        b = XYZ(self.slope + change_factor, self.intercept)\n",
    "        c = XYZ(self.slope, self.intercept + change_factor)\n",
    "        b.get_gsr()\n",
    "        c.get_gsr()\n",
    "        #print(b)\n",
    "        #print(c)\n",
    "        #print(\"change_factor\", change_factor)\n",
    "        return b, c\n",
    "    \n",
    "    def create_new_base(self):\n",
    "        b, c = self.get_points()\n",
    "        coord_change_values = self.delta_vector(b, c)\n",
    "        curr_coord = [self.slope, self.intercept]\n",
    "        new_coord = [curr_coord[0]+coord_change_values[0], curr_coord[1]+coord_change_values[1]]\n",
    "        return XYZ(new_coord[0], new_coord[1])\n",
    "    \n",
    "    def __repr__(self):\n",
    "        slope_and_int = \"Slope: \" + str(round(self.slope, 5)) + \"  Intercept: \" + str(round(self.intercept, 5))\n",
    "        if self.has_gsr():\n",
    "            return slope_and_int + \"  GSR: \" +  str(round(self.gsr, 5))\n",
    "        return slope_and_int\n",
    "            \n",
    "    def __str__(self):\n",
    "        return self.__repr__()\n",
    "        \n",
    "#------------------------------------------------------------------------------------------------------------------------------#\n",
    "def test_values(slope, intercept):\n",
    "    ##   a = slope*b + intercept   ##\n",
    "    # optimal values are: \n",
    "    return test_runner(slope, intercept)\n",
    "    \n",
    "def optimize_slope_and_intercept():\n",
    "    print(\"Beginning Optimization Procedures!\")\n",
    "    base = XYZ(-1, 1) \n",
    "    base.get_gsr()\n",
    "    margin_of_error = 0.1\n",
    "    run_count = 0\n",
    "    while base.gsr > margin_of_error+1 and run_count < 20:\n",
    "        print(\"\\nnew base\", base)\n",
    "        base = base.create_new_base()\n",
    "        base.get_gsr()\n",
    "        run_count += 3\n",
    "    print(\"--------------------------------\")\n",
    "    print(\"final base:\", base)\n",
    "    print(\"run_count\", run_count)\n",
    "    return base, run_count\n",
    "\n",
    "start_time = datetime.datetime.now()\n",
    "final_base, computations = optimize_slope_and_intercept()\n",
    "end_time = atetime.datetime.now()\n",
    "print('\\n\\n\\n\\n')\n",
    "print(\"Optimal Solution:\", final_base)\n",
    "print(\"computed in\", run_count, \"iterations.\")\n",
    "print(\"Total Time Elapsed:\", end_time - start_time, \"(from \" + start_time + \" to \" + end_time + \")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"          \n",
    "                 a   b\n",
    "                     d   e\n",
    "                 c       g\n",
    "                     f          \n",
    "                                       \n",
    "                                               \n",
    "                                                    •\n",
    "                        \n",
    "                        \n",
    "first, we take the three points as our starters\n",
    "we find the rate of change between them, (∆GSR/∆slope or ∆intercept)\n",
    "move in the direction of the change between points times the rates of change\n",
    "a(0,0) = 10\n",
    "b(1,0) = 9\n",
    "c(0,1) = 9.5\n",
    "∆ab = 1/1   = 1               #a - b\n",
    "∆ac = 0.5/1 = -0.5           #a - c\n",
    "(b-a)*∆ab = <1,0>*1   = <1,0>\n",
    "(c-a)*∆ac = <0,1>*0.5 = <0,0.5>\n",
    "d(1,0.5) = 8.5\n",
    "e(2,0.5) = 7.5\n",
    "f(1,1.5) = 8\n",
    "∆de = 1/1   = 1\n",
    "∆df = 0.5/1 = 0.5\n",
    "(e-d)*∆de = <1,0>*1   = <1,0>\n",
    "(f-d)*∆df = <0,1>*0.5 = <0,0.5>\n",
    "<1,0> + <0,0.5> = <1,0.5>\n",
    "<1,0.5>+<1,0.5> = <2,1>\n",
    "g(2,1)\n",
    "...\n",
    "...\n",
    "...\n",
    "\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"def test_values(slope, intercept):\n",
    "    ##   a = slope*b + intercept   ##\n",
    "    # optimal values are: slope=6.2, intercept=7.5\n",
    "    return abs((slope-6.2)) + abs((intercept-7.5))\n",
    "    \n",
    "class XYZ:\n",
    "    def __init__(self, slope, intercept, gsr):\n",
    "        self.slope = slope\n",
    "        self.intercept = intercept\n",
    "        self.gsr = gsr\n",
    "    \n",
    "def optimize():\n",
    "    run_count = 0\n",
    "    def optimize_slope(min_slope, max_slope, intercept):\n",
    "        nonlocal run_count\n",
    "        mean_slope, gsr_dict = (min_slope + max_slope)/2, {} \n",
    "        slope_dict = {\"min_slope\": min_slope, \"max_slope\": max_slope}  #, \"mean_slope\": mean_slope}\n",
    "        for key in slope_dict:\n",
    "            slope = slope_dict[key]\n",
    "            if slope in output_dict:\n",
    "                gsr_dict[slope] = output_dict[slope]\n",
    "            else:\n",
    "                run_count += 1\n",
    "                gsr_dict[slope] = test_values(slope, intercept)\n",
    "        print(\"min_slope:\", slope_dict[\"min_slope\"], \"gsr_min:\", gsr_dict[slope_dict[\"min_slope\"]])\n",
    "        print(\"max_slope:\", slope_dict[\"max_slope\"], \"gsr_max:\", gsr_dict[slope_dict[\"max_slope\"]])\n",
    "        #print(\"mean_slope:\",slope_dict[\"mean_slope\"],\"gsr_mean:\",gsr_dict[slope_dict[\"mean_slope\"]])\n",
    "        #gsr_dict = {min_slope: gsr_min, max_slope: gsr_max, mean_slope: gsr_mean}\n",
    "        return gsr_dict\n",
    "\n",
    "    def optimize_slope(min_int, max_int, slope):\n",
    "        nonlocal run_count\n",
    "        mean_int, gsr_dict = (min_int + max_int)/2, {} \n",
    "        slope_dict = {\"min_int\": min_int, \"max_int\": max_int}     #, \"mean_int\": mean_int}\n",
    "        for key in slope_dict:\n",
    "            slope = slope_dict[key]\n",
    "            if slope in output_dict:\n",
    "                gsr_dict[slope] = output_dict[slope]\n",
    "            else:\n",
    "                run_count += 1\n",
    "                gsr_dict[slope] = test_values(slope, intercept)\n",
    "        print(\"min_int:\", slope_dict[\"min_int\"], \"gsr_min:\", gsr_dict[slope_dict[\"min_int\"]])\n",
    "        print(\"max_int:\", slope_dict[\"max_int\"], \"gsr_max:\", gsr_dict[slope_dict[\"max_int\"]])\n",
    "        #print(\"mean_int:\",slope_dict[\"mean_int\"],\"gsr_mean:\",gsr_dict[slope_dict[\"mean_int\"]])\n",
    "        #gsr_dict = {min_int: gsr_min, max_int: gsr_max, mean_int: gsr_mean}\n",
    "        return gsr_dict\n",
    "    \n",
    "    def remove_and_print_biggest(dict_in):\n",
    "        print( \"biggest:\", dict_in.pop([key for key in dict_in if dict_in[key] ==  max([dict_in[key] for key in dict_in])  ][0]) )\n",
    "    \n",
    "    def key_of_fn_val(dict_in, fn):\n",
    "        return [key for key in dict_in if dict_in[key] ==  fn([dict_in[key] for key in dict_in])  ][0]\n",
    "    \n",
    "    def update_dict_from_another(dict_to, dict_from):\n",
    "        for key in dict_from:                   # for each key in the dict we're copying from\n",
    "            if key not in dict_to:              # if they key isn't in the dictionary we're copying to\n",
    "                dict_to[key] = dict_from[key]   # copy the key-value pair to the other dictionary\n",
    "    \n",
    "    def return_statement(dict_in):    \n",
    "        min_val_key = [key for key in dict_in if dict_in[key] ==  min([dict_in[key] for key in dict_in])  ][0]\n",
    "        smallest_output = min([dict_in[key] for key in dict_in])\n",
    "        biggest_output = max([dict_in[key] for key in dict_in])\n",
    "        print(\"run_count:\", run_count)\n",
    "        return min_val_key, smallest_output, biggest_output-smallest_output, dict_in\n",
    "    \n",
    "    margin_of_error, intercept = 0.1, 5.5\n",
    "    dict_in, output_dict = {0:50, 10:100, 61:715}, {} #starting guesses for dictionary (values useless)\n",
    "    while max([dict_in[key] for key in dict_in]) - min([dict_in[key] for key in dict_in]) > margin_of_error:\n",
    "        remove_and_print_biggest(dict_in)                                   #remove the least accurate guess\n",
    "        min_val_key = key_of_fn_val(dict_in, min)                           #get the key with the smallest value\n",
    "        max_val_key = key_of_fn_val(dict_in, max)                           #get the key with the largest value\n",
    "        dict_in = optimize_slope(min_val_key, max_val_key, intercept)       #test the new values\n",
    "        update_dict_from_another(output_dict, dict_in)                      #update memoized dictionary from the slope/gsr dict\n",
    "        print(\"memoized dictionary:\", output_dict)                          #print memoized dictionary\n",
    "        print(\"new_updates:\", dict_in)                                      #print slope/gsr dictionary\n",
    "        \n",
    "    return return_statement(dict_in)\n",
    "\n",
    "#make note of when the answer is very close to the boundary, means boundary change is needed\n",
    "print('Begin!')        \n",
    "optimize()\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
